{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLKgKf8uYJWJSUkfTKYRpy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geekevgin/-Python/blob/main/Untitled46.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5uLcOMjw2-6l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import asarray\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_pdo_e68Yba5",
        "outputId": "9080d326-a84b-4928-ad62-9e210a612184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 тренировочные примеры\n",
            "10000 тестовые примеры\n",
            "Использование data augmentation в реальном времени\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-ec5581491e5c>:112: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(x_train, y_train,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000/1000 [==============================] - 210s 209ms/step - loss: 1.7525 - accuracy: 0.3423 - val_loss: 1.3290 - val_accuracy: 0.5059\n",
            "Epoch 2/15\n",
            "1000/1000 [==============================] - 198s 197ms/step - loss: 1.3554 - accuracy: 0.5060 - val_loss: 1.1699 - val_accuracy: 0.5777\n",
            "Epoch 3/15\n",
            "1000/1000 [==============================] - 192s 192ms/step - loss: 1.1993 - accuracy: 0.5733 - val_loss: 1.0026 - val_accuracy: 0.6406\n",
            "Epoch 4/15\n",
            "1000/1000 [==============================] - 194s 194ms/step - loss: 1.0921 - accuracy: 0.6138 - val_loss: 0.9544 - val_accuracy: 0.6619\n",
            "Epoch 5/15\n",
            "1000/1000 [==============================] - 191s 191ms/step - loss: 1.0167 - accuracy: 0.6448 - val_loss: 0.8182 - val_accuracy: 0.7084\n",
            "Epoch 6/15\n",
            "1000/1000 [==============================] - 192s 192ms/step - loss: 0.9626 - accuracy: 0.6637 - val_loss: 0.8437 - val_accuracy: 0.7073\n",
            "Epoch 7/15\n",
            "1000/1000 [==============================] - 192s 191ms/step - loss: 0.9245 - accuracy: 0.6765 - val_loss: 0.8469 - val_accuracy: 0.7005\n",
            "Epoch 8/15\n",
            "1000/1000 [==============================] - 191s 191ms/step - loss: 0.8914 - accuracy: 0.6922 - val_loss: 0.7992 - val_accuracy: 0.7196\n",
            "Epoch 9/15\n",
            "1000/1000 [==============================] - 191s 191ms/step - loss: 0.8690 - accuracy: 0.7007 - val_loss: 0.8547 - val_accuracy: 0.7008\n",
            "Epoch 10/15\n",
            "1000/1000 [==============================] - 192s 191ms/step - loss: 0.8514 - accuracy: 0.7056 - val_loss: 0.9370 - val_accuracy: 0.6954\n",
            "Epoch 11/15\n",
            "1000/1000 [==============================] - 192s 192ms/step - loss: 0.8303 - accuracy: 0.7135 - val_loss: 0.6956 - val_accuracy: 0.7586\n",
            "Epoch 12/15\n",
            "1000/1000 [==============================] - 192s 192ms/step - loss: 0.8092 - accuracy: 0.7212 - val_loss: 0.7291 - val_accuracy: 0.7516\n",
            "Epoch 13/15\n",
            "1000/1000 [==============================] - 191s 191ms/step - loss: 0.7998 - accuracy: 0.7251 - val_loss: 0.7038 - val_accuracy: 0.7554\n",
            "Epoch 14/15\n",
            "1000/1000 [==============================] - 191s 191ms/step - loss: 0.7900 - accuracy: 0.7294 - val_loss: 0.7338 - val_accuracy: 0.7519\n",
            "Epoch 15/15\n",
            "1000/1000 [==============================] - 192s 192ms/step - loss: 0.7819 - accuracy: 0.7312 - val_loss: 0.6709 - val_accuracy: 0.7740\n",
            "сохранить обученную модель как /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.6709 - accuracy: 0.7740\n",
            "Test loss: 0.6709437966346741\n",
            "Test accuracy: 0.7739999890327454\n"
          ]
        }
      ],
      "source": [
        "# увеличить batch_size до 50, epochs до 15, добавить еще слой НС, оптимайзер Adam.\n",
        "# улучшает рабоут увеличение количества эпоx, bathes, дополниетльный слой\n",
        "from __future__ import print_function\n",
        "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "# установка параметров нейросети\n",
        "batch_size = 50\n",
        "num_classes = 10\n",
        "epochs = 15\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# разделение тренировочной и тестовой выборки\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'тренировочные примеры')\n",
        "print(x_test.shape[0], 'тестовые примеры')\n",
        "\n",
        "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# конфигурирование слоев нейросети\n",
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# инициализация RMSprop optimizer\n",
        "opt = keras.optimizers.Adam()\n",
        "# компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Не используется data augmentation')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Использование data augmentation в реальном времени')\n",
        "    # Препроцессинг и data augmentation в реальном времени:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0., \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # запуск data augmentation через fit\n",
        "    #datagen.fit(x_train)\n",
        "\n",
        "    # запуск data augmentation через fit_generator\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# сохранение модели и весов\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('сохранить обученную модель как %s ' % model_path)\n",
        "\n",
        "# проверка работы обученной модели\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "outputId": "d3a76ece-022c-4c53-b40c-8c9a6cf23e98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_z8Dg0sEWph"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 тренировочные примеры\n",
            "10000 тестовые примеры\n",
            "Использование data augmentation в реальном времени\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c6a18446c7d2>:114: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(x_train, y_train,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "715/715 [==============================] - 190s 265ms/step - loss: 1.7496 - accuracy: 0.3399 - val_loss: 1.3527 - val_accuracy: 0.4950\n",
            "Epoch 2/10\n",
            "715/715 [==============================] - 190s 265ms/step - loss: 1.3455 - accuracy: 0.5097 - val_loss: 1.2176 - val_accuracy: 0.5692\n",
            "Epoch 3/10\n",
            "715/715 [==============================] - 189s 264ms/step - loss: 1.1958 - accuracy: 0.5723 - val_loss: 1.0650 - val_accuracy: 0.6225\n",
            "Epoch 4/10\n",
            "715/715 [==============================] - 189s 264ms/step - loss: 1.0841 - accuracy: 0.6168 - val_loss: 0.9305 - val_accuracy: 0.6698\n",
            "Epoch 5/10\n",
            "715/715 [==============================] - 190s 266ms/step - loss: 1.0152 - accuracy: 0.6440 - val_loss: 0.8792 - val_accuracy: 0.7000\n",
            "Epoch 6/10\n",
            "715/715 [==============================] - 190s 265ms/step - loss: 0.9542 - accuracy: 0.6649 - val_loss: 0.7912 - val_accuracy: 0.7257\n",
            "Epoch 7/10\n",
            "715/715 [==============================] - 188s 263ms/step - loss: 0.9085 - accuracy: 0.6841 - val_loss: 0.7411 - val_accuracy: 0.7451\n",
            "Epoch 8/10\n",
            "715/715 [==============================] - 188s 263ms/step - loss: 0.8740 - accuracy: 0.6954 - val_loss: 0.7561 - val_accuracy: 0.7384\n",
            "Epoch 9/10\n",
            "715/715 [==============================] - 189s 264ms/step - loss: 0.8555 - accuracy: 0.7025 - val_loss: 0.7609 - val_accuracy: 0.7366\n",
            "Epoch 10/10\n",
            "715/715 [==============================] - 189s 264ms/step - loss: 0.8283 - accuracy: 0.7138 - val_loss: 0.8549 - val_accuracy: 0.7095\n",
            "сохранить обученную модель как /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "313/313 [==============================] - 9s 29ms/step - loss: 0.8549 - accuracy: 0.7095\n",
            "Test loss: 0.8549185395240784\n",
            "Test accuracy: 0.7095000147819519\n"
          ]
        }
      ],
      "source": [
        "# увеличить batch_size до 50, epochs до 15, добавить еще слой НС, оптимайзер Adam.\n",
        "# улучшает рабоут увеличение количества эпоx, bathes, дополниетльный слой\n",
        "from __future__ import print_function\n",
        "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "# установка параметров нейросети\n",
        "batch_size = 70\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# разделение тренировочной и тестовой выборки\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'тренировочные примеры')\n",
        "print(x_test.shape[0], 'тестовые примеры')\n",
        "\n",
        "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# конфигурирование слоев нейросети\n",
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# инициализация RMSprop optimizer\n",
        "opt = keras.optimizers.Adam()\n",
        "# компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Не используется data augmentation')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Использование data augmentation в реальном времени')\n",
        "    # Препроцессинг и data augmentation в реальном времени:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0., \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # запуск data augmentation через fit\n",
        "    #datagen.fit(x_train)\n",
        "\n",
        "    # запуск data augmentation через fit_generator\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# сохранение модели и весов\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('сохранить обученную модель как %s ' % model_path)\n",
        "\n",
        "# проверка работы обученной модели\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Практическое задание\n",
        "# 2. Изменение размера batch_size, ширина и высота изображения(в mnist - 28), количество эпох, изменение количесва классов(ciraf100 = 100), увеличение скрытых слоев(ciraf 100)"
      ],
      "metadata": {
        "id": "SR-Q-sCQbLpO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}